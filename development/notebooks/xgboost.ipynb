{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id'], inplace=True)\n",
    "df[\"outcome\"] = df[\"outcome\"].replace({\"died\": 0, \"lived\": 1, \"euthanized\": 2})\n",
    "df.fillna('empty', inplace=True)\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"outcome\"])\n",
    "y = df[\"outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=0, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, _X, _y):\n",
    "    model.fit(_X, _y)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(_model, _X, _y):\n",
    "    \n",
    "    result = _model.predict(_X)\n",
    "    \n",
    "    print(accuracy_score(result, _y))\n",
    "    print()\n",
    "    print(confusion_matrix(result, _y, labels=[1, 0, -1]))\n",
    "    print()\n",
    "    print(classification_report(result, _y, labels=[1, 0, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(_model, df_test, _X_train):\n",
    "    id = df_test['id'].to_list()\n",
    "\n",
    "    df_test.drop(columns=['id'], inplace=True)\n",
    "    df_test.fillna('empty', inplace=True)\n",
    "    df_test = pd.get_dummies(df_test)\n",
    "\n",
    "    df_test['peristalsis_distend_small'] = False\n",
    "    df_test['nasogastric_reflux_slight'] = False\n",
    "    df_test['rectal_exam_feces_serosanguious'] = False\n",
    "\n",
    "    df_test.rename(columns={'pain_moderate': 'pain_slight'}, inplace=True)\n",
    "\n",
    "    df_test = df_test[_X_train.columns.to_list()]\n",
    "\n",
    "    result = _model.predict(df_test)\n",
    "\n",
    "    df_submission = pd.DataFrame(data={'id': id ,'outcome': list(result)})\n",
    "    df_submission[\"outcome\"] = df_submission[\"outcome\"].replace({0: \"died\", 1: \"lived\", 2: \"euthanized\"})\n",
    "    df_submission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "df_test = pd.read_csv(\"../../data/test.csv\")\n",
    "df_test.head()\n",
    "parameters = {\n",
    "    \"max_depth\": list(np.arange(10, 100, 10)),\n",
    "    \"learning_rate\": list(np.arange(0.01, 1.1, .1)),\n",
    "    \"subsample\": list(np.arange(0.1, 1.1, 0.1))\n",
    "}\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "model = train(XGBClassifier(), ss.fit_transform(X_train), y_train)\n",
    "submit(model, df_test, X_train, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# df_test = pd.read_csv(\"../../data/test.csv\")\n",
    "# df_test.head()\n",
    "# parameters = {\n",
    "#     \"max_depth\": list(np.arange(10, 100, 10)),\n",
    "#     \"learning_rate\": list(np.arange(0.01, 1.1, .1)),\n",
    "#     \"subsample\": list(np.arange(0.1, 1.1, 0.1))\n",
    "# }\n",
    "# grid = GridSearchCV(estimator=XGBClassifier(), param_grid=parameters, cv=10, n_jobs=-1)\n",
    "# model = train(grid, X_train, y_train)\n",
    "# submit(model, df_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter grid for parameter 'objective' needs to be a list or a numpy array, but got 'multi:softprob' (of type str) instead. Single values need to be wrapped in a list with one element.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\Health-Outcomes-of-Horses\\development\\notebooks\\xgboost.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m parameters \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmulti:softprob\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtree_method\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhist\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39meta\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m.03\u001b[39m}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mXGBClassifier(), param_grid\u001b[39m=\u001b[39mparameters, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m train(grid, X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m submit(model, df_test, X_train)\n",
      "\u001b[1;32mc:\\GitHub\\Health-Outcomes-of-Horses\\development\\notebooks\\xgboost.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, _X, _y):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(_X, _y)    \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Health-Outcomes-of-Horses/development/notebooks/xgboost.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:119\u001b[0m, in \u001b[0;36mParameterGrid.__init__\u001b[1;34m(self, param_grid)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter array for \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m should be one-dimensional, got:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m with shape \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    117\u001b[0m     value, (np\u001b[39m.\u001b[39mndarray, Sequence)\n\u001b[0;32m    118\u001b[0m ):\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    120\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter grid for parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m needs to be a list or a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m numpy array, but got \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m (of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m) instead. Single values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mneed to be wrapped in a list with one element.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m     )\n\u001b[0;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    126\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    127\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter grid for parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m need \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto be a non-empty sequence, got: \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Parameter grid for parameter 'objective' needs to be a list or a numpy array, but got 'multi:softprob' (of type str) instead. Single values need to be wrapped in a list with one element."
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "df_test = pd.read_csv(\"../../data/test.csv\")\n",
    "df_test.head()\n",
    "parameters = {\"objective\": \"multi:softprob\", \"tree_method\": \"hist\",\"num_class\": 3,\"eta\":.03}\n",
    "grid = GridSearchCV(estimator=XGBClassifier(), param_grid=parameters, cv=10, n_jobs=-1)\n",
    "model = train(grid, X_train, y_train)\n",
    "submit(model, df_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\GitHub\\Health-Outcomes-of-Horses\\venv\\lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "df_test = pd.read_csv(\"../../data/test.csv\")\n",
    "df_test.head()\n",
    "parameters = {\"objective\": \"multi:softprob\", \"tree_method\": \"hist\",\"num_class\": 3,\"eta\": .03}\n",
    "grid = XGBClassifier(**parameters)\n",
    "model = train(grid, X_train, y_train)\n",
    "submit(model, df_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
